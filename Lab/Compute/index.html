<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Lab/Compute/README">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.1.0">
<title data-rh="true">Compute | Operating Systems</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="http://localhost//Lab/Compute/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Compute | Operating Systems"><meta data-rh="true" name="description" content="The main criterion we use to rank CPUs is their computation power, i.e. their ability to crunch numbers and do math."><meta data-rh="true" property="og:description" content="The main criterion we use to rank CPUs is their computation power, i.e. their ability to crunch numbers and do math."><link data-rh="true" rel="canonical" href="http://localhost//Lab/Compute/"><link data-rh="true" rel="alternate" href="http://localhost//Lab/Compute/" hreflang="en"><link data-rh="true" rel="alternate" href="http://localhost//Lab/Compute/" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.17f22a47.css">
<link rel="preload" href="/assets/js/runtime~main.55192f6a.js" as="script">
<link rel="preload" href="/assets/js/main.1070cd52.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="theme.common.skipToMainContent"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">SO</b></a><a class="navbar__item navbar__link" href="/Lecture">Lecture</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Lab">Lab</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Lecture/">Lecture</a><button aria-label="Toggle the collapsible sidebar category &#x27;Lecture&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/Lab/">Lab</a><button aria-label="Toggle the collapsible sidebar category &#x27;Lab&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Lab/Compute/">Compute</a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Lab/"><span itemprop="name">Lab</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Compute</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Compute</h1><p>The main criterion we use to rank CPUs is their <em>computation power</em>, i.e. their ability to crunch numbers and do math.
Numerous benchmarks exist out there and they are publicly displayed on websites such as <a href="https://www.cpubenchmark.net/" target="_blank" rel="noopener noreferrer">CPUBenchmark</a>.</p><p>This benchmark measures the performance of the computer&#x27;s CPU in a variety of scenarios:</p><ul><li>its ability to perform integer operations</li><li>its speed in floating point arithmetic</li><li>data encryption and compression</li><li>sorting algorithms and others</li></ul><p>You can take a look at what exactly is measured using <a href="https://www.cpubenchmark.net/cpu.php?cpu=AMD+Ryzen+Threadripper+PRO+5995WX" target="_blank" rel="noopener noreferrer">this link</a>.
It displays the scores obrtained by a high-end CPU.
Apart from the tests above, other benchmarks can also focus on other performance metrics such as branch prediction or prefetching.</p><p>Other approaches are less artificial, measuring performance on real-world applications such as compile times and performance in the lastest (and most resource-demandign) video games.
The latter metric revolves around how many average FPS (frames per second) a given CPU is able to crank out in a specific video game.
<a href="https://www.gamersnexus.net/guides/3577-cpu-test-methodology-unveil-for-2020-compile-gaming-more" target="_blank" rel="noopener noreferrer">This article</a> goes into more detail regarding the methodology of running CPU benchmarks on real-world applications.</p><p>Most benchmarks, unfortunately, are not open source, especially the more popular ones, such as <a href="https://browser.geekbench.com/processor-benchmarks" target="_blank" rel="noopener noreferrer">Geekbench 5</a>.
Despite this shortcoming, benchmarks are widely used to compare the performance of various computer <strong>hardware</strong>, CPUs included.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-role-of-the-operating-system">The Role of the Operating System<a class="hash-link" href="#the-role-of-the-operating-system" title="Direct link to heading">​</a></h2><p>As you&#x27;ve seen so far, the CPU provides the &quot;muscle&quot; requried for fast computation. i.e. the highly optimised hardware and multiple ALUs, FPUs
and cores necessary to perform those computations.
However, it is the <strong>operating system</strong> that provides the &quot;brains&quot; for this computation.
Specifically, modern CPUs have the capacity to run multiple tasks in parallel.
But they do not provide a means to decide which task to run at each moment.
The OS comes as an <em>orchestrator</em> to <strong>schedule</strong> the way these tasks (that we will later call threads) are allowed to run and use the CPU&#x27;s resources.
This way OS tells the CPU what code to run on each CPU core so that it reaches a good balance between high throughput (running many instructions) and fair access to CPU cores.</p><p>It is cumbersome for a user-level application to interact directly with the CPU.
The developer would have to write hardware-specific code which is not scalable and is difficult to maintain.
In addition, doing so would leave it up to the developer to isolate their application from the others that are present on the system.
This leaves applications vulnerable to countless bugs and exploits.</p><p>To guard apps from these pitfalls, the OS comes and mediates interactions between regular programs and the CPU by providing a set of <strong>abstractions</strong>.
These abstractions offer a safe, uniform and also isolated way to leverage the CPU&#x27;s resources, i.e. its cores.
There are 2 main abstractions: <strong>processes</strong> and <strong>threads</strong>.</p><p><img loading="lazy" alt="Interaction between applications, OS and CPU" src="/assets/images/app-os-cpu-interaction-ca7fbdbb7da380e0992c95467ef267ce.svg" width="772" height="772" class="img_ev3q"></p><p>As we can see from the image above, an application can spawn one or more processes.
Each of these is handled and maintained by the OS.
Similarly, each process can spawn however many threads, which are also managed by the OS.
The OS decides when and on what CPU core to make each thread run.
This is in line with the general of interaction between an application and the hardware: it is always mediated by the OS.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="processes">Processes<a class="hash-link" href="#processes" title="Direct link to heading">​</a></h2><p>A process is simply a running program.
Let&#x27;s take the <code>ls</code> command as a trivial example.
<code>ls</code> is a <strong>program</strong> on your system.
It has a binary file which you can find and inspect with the help of the <code>which</code> command:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~$ which ls</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/usr/bin/ls</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~$ file /usr/bin/ls</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/usr/bin/ls: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=6e3da6f0bc36b6398b8651bbc2e08831a21a90da, for GNU/Linux 3.2.0, stripped</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>When you run it, the <code>ls</code> binary stored <strong>on the disk</strong> at <code>/usr/bin/ls</code> is read by another application called the <strong>loader</strong>.
The loader spawns a <strong>process</strong> by copying some of the contents <code>/usr/bin/ls</code> in memory (such as the <code>.text</code>, <code>.rodata</code> and <code>.data</code> sections).
Using <code>strace</code>, we can see the <a href="https://man7.org/linux/man-pages/man2/execve.2.html" target="_blank" rel="noopener noreferrer"><code>execve</code></a> system call:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~$ strace -s 100 ls -a  # -s 100 limits strings to 100 bytes instead of the default 32</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">execve(&quot;/usr/bin/ls&quot;, [&quot;ls&quot;, &quot;-a&quot;], 0x7fffa7e0d008 /* 61 vars */) = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">write(1, &quot;.  ..  content\tCONTRIBUTING.md  COPYING.md  .git  .gitignore  README.md  REVIEWING.md\n&quot;, 86.  ..  content   CONTRIBUTING.md  COPYING.md  .git  .gitignore  README.md  REVIEWING.md</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">) = 86</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">close(1)                                = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">close(2)                                = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">exit_group(0)                           = ?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ exited with 0 +++</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Look at its parameters:</p><ul><li>the path to the <strong>program</strong>: <code>/usr/bin/ls</code></li><li>the list of arguments: <code>&quot;ls&quot;, &quot;-a&quot;</code></li><li>the enivronment variables: the rest of the syscall&#x27;s arguments</li></ul><p><code>execve</code> invokes the loader to create the <code>ls</code> process.
All subsequent syscalls are performed by the newly spawned <code>ls</code> process.
We will get into more details regarding <code>execve</code> <a href="#TODO-section">towards the end of this lab</a>.</p><p>TODO - image: creation of a process - loader</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sum-of-the-elements-in-an-array">Sum of the Elements in an Array<a class="hash-link" href="#sum-of-the-elements-in-an-array" title="Direct link to heading">​</a></h2><p>Let&#x27;s assume we only have one process on our system and that process knows how to add the numbers in an array.
It can use however many resources it wants since there is no other process to contest it.
It would probabily look like the code in <code>support/sum-array/d/sum_array_sequential.d</code>.
The program also measures the time spent computing the sum.
Let&#x27;s compile and run it:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/sum-array/d$ ./sum_array_sequential</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Array sum is: 49945994146</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Time spent: 127 ms</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You will most likely get a different sum (because the array is made up of random numbers) and a different time than the ones shown above.
This is perfectly fine.
Use these examples qualitatively, not quantitatively.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="spreading-the-work-among-other-processes">Spreading the Work Among Other Processes<a class="hash-link" href="#spreading-the-work-among-other-processes" title="Direct link to heading">​</a></h3><p>Due to how it&#x27;s implemented so far, our program only uses one of our CPU&#x27;s cores.
We never tell it to distribute its workload on other cores.
This is wasteful as the rest of our cores remain unused:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~$ lscpu | grep ^CPU\(s\):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CPU(s):                          8</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We have 7 more cores waiting to add numbers in our array.</p><p><img loading="lazy" alt="What if we used 100% of the CPU?" src="/assets/images/100-percent-cpu-1138186529f154d864f643179e25cea1.jpeg" width="541" height="500" class="img_ev3q"></p><p>What if we use 7 more processes between which we spread the task of adding the numbers in this array?
If we split the array into several equal parts and designate a separate process to calculate the sum of each part, we should get a speedup because now the work performed by each individual process is reduced.</p><p>Let&#x27;s take it methodically.
Compile and run <code>sum_array_processes.d</code> using 1, 2, 4 and 8 processes respectively.
If your system only has 4 cores (<a href="https://www.intel.com/content/www/us/en/gaming/resources/hyper-threading.html" target="_blank" rel="noopener noreferrer">hyperthreading</a> included), limit your runs to 4 processes.
Note the running times for each number of processes.
We expect the speedups compared to our reference run to be 1, 2, 4 and 8 respectively, right?</p><p><a href="/Lab/Compute/quiz/processes-speedup">Quiz</a></p><p>You most likely did get some speedup, especially when using 8 processes.
Now we will try to improve this speedup by using <strong>threads</strong> instead.</p><p>Also notice that we&#x27;re not using hundreds or thousands of processes.
Assuming our system has 8 cores, only 8 <em>threads</em> (we&#x27;ll see this later in the lab) can run at the same time.
In general, <strong>the maximum number of threads that can run at the same time is equal to the number of cores</strong>.
In our example, each process only has one thread: its main thread.
So by consequence and by forcing the terminology (because it&#x27;s the main thread of these processes that is running, not the processes themselves), we can only run in parallel a number of processes equal to at most the number of cores.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-baby-steps---python">Practice: Baby steps - Python<a class="hash-link" href="#practice-baby-steps---python" title="Direct link to heading">​</a></h4><p>Run the code in <code>support/create-process/popen.py</code>.
It simply spawns a new process running the <code>ls</code> command using <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen" target="_blank" rel="noopener noreferrer"><code>subprocess.Popen()</code></a>.
Do not worry about the huge list of arguments that <code>Popen()</code> takes.
They are used for inter-process-communication.
You&#x27;ll learn more about this in the <a href="/app-interact/">Application Interaction chapter</a>.</p><p>Note that this usage of <code>Popen()</code> is not entirely correct.
You&#x27;ll discover why in the next exercise, but for now focus on simply understanding how to use <code>Popen()</code> on its own.</p><p>Now change the command to anything you want.
Also give it some arguments.
From the outside, it&#x27;s as if you were running these commands from the terminal.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-high-level---python">Practice: High level - Python<a class="hash-link" href="#practice-high-level---python" title="Direct link to heading">​</a></h4><p>Head over to <code>support/sleepy/sleepy_creator.py</code>.
Use <code>subprocess.Popen()</code> to spawn 10 <code>sleep 1000</code> processes.</p><ol><li>Now use the same <code>pstree -pac</code> command and look for <code>sleepy_creator.py</code>.
It is a <code>python3</code> process, as this is the interpreter that runs the script, but we call it the <code>sleepy_creator.py</code> process for simplicity.
If you found it, you did something wrong.
It should be missing.
Now use <code>pstree -pac</code> and look for the <code>sleep</code> processes you have just created.</li></ol><p><a href="/Lab/Compute/quiz/parent-of-sleep-processes">Quiz</a></p><ol start="2"><li>Change the code in <code>sleepy_creator.py</code> so that the <code>sleep 1000</code> processes are the children of <code>sleepy_creator.py</code>.
Kill the previously created <code>sleep</code> processes using <code>killall sleep</code>.
Verify that <code>sleepy_creator.py</code> remains the parent of the <code>sleep</code>s it creates using <code>pstree -pac</code>.</li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-lower-level---c">Practice: Lower level - C<a class="hash-link" href="#practice-lower-level---c" title="Direct link to heading">​</a></h4><p>Now let&#x27;s see how to create a child process in C.
There are multiple ways of doing this.
For now, we&#x27;ll start with a higher-level approach.</p><p>Go to <code>support/sleepy/sleepy_creator.c</code> and use <a href="https://man7.org/linux/man-pages/man3/system.3.html" target="_blank" rel="noopener noreferrer"><code>system</code></a> to create a <code>sleep 1000</code> process.</p><p><a href="/Lab/Compute/quiz/create-sleepy-process-ending">Quiz</a></p><p>The <code>man</code> page also mentions that <code>system</code> calls <code>fork()</code> and <code>exec()</code> to run the command it&#x27;s given.
If you want to find out more about them, head over to the <a href="#mini-shell">Arena and create your own mini-shell</a>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-wait-for-me">Practice: Wait for Me!<a class="hash-link" href="#practice-wait-for-me" title="Direct link to heading">​</a></h4><p>Run the code in <code>support/wait-for-me/wait_for_me_processes.py</code>.
The parent process creates one child that writes and message to the given file.
Then the parent reads that message.
Simple enough, right?
But running the code raises a <code>FileNotFoundError</code>.
If you inspect the file you gave the script as an argument, it does contain a string.
What&#x27;s going on?</p><p><a href="/Lab/Compute/quiz/cause-of-file-not-found-error">Quiz</a></p><p>In order to solve race conditions, we need <strong>synchronisation</strong>.
This is a mechanism similar to a set of traffic lights in a crossroads.
Just like traffic lights allow some cars to pass only after others have already passed, synchronisation is a means for threads to communicate with each other and tell each other to access a resource or not.</p><p>The most basic form of synchronisation is <strong>waiting</strong>.
Concretely, if the parent process <strong>waits</strong> for the child to end, we are sure the file is created and its contents are written.
Use <code>join()</code> to make the parent wait for its child before reading the file.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-fork">Practice: <code>fork()</code><a class="hash-link" href="#practice-fork" title="Direct link to heading">​</a></h4><p>Up to now we&#x27;ve been creating processes using various high-level APIs, such as <code>Popen()</code>, <code>Process()</code> and <code>system()</code>.
Yes, despite being a C function, as you&#x27;ve seen from its man page, <code>system()</code> itself calls 2 other functions: <code>fork()</code> to create a process and <code>execve()</code> to execute the given command.
As you already know from the <a href="/software-stack/">Software Stack</a> chapter, library functions may call one or more underlying system calls or other functions.
Now we will move one step lower on the call stack and call <code>fork()</code> ourselves.</p><p><code>fork()</code> creates one child process that is <em>almost</em> identical to its parent.
We say that <code>fork()</code> returns <strong>twice</strong>: once in the parent process and once more in the child process.
This means that after <code>fork()</code> returns, assuming no error has occurred, both the child and the parent resume execution from the same place: the instruction following the call to <code>fork()</code>.
What&#x27;s different between the two processes is the value returned by <code>fork()</code>:</p><ul><li><strong>child process</strong>: <code>fork()</code> returns 0</li><li><strong>parent process</strong>: <code>fork()</code> returns the PID of the child process (&gt; 0)</li><li><strong>on error</strong>: <code>fork()</code> returns -1, only once, in the initial process</li></ul><p>Therefore, the typical code for handling a <code>fork()</code> is available in <code>support/create-process/fork.c</code>.
Take a look at it and then run it.
Notice what each of the two processes prints:</p><ul><li>the PID of the child is also known by the parent</li><li>the PPID of the child is the PID of the parent</li></ul><p>Unlike <code>system()</code>, who also waits for its child, when using <code>fork()</code> we must do the waiting ourselves.
In order to wait for a process to end, we use the <a href="https://linux.die.net/man/2/waitpid" target="_blank" rel="noopener noreferrer"><code>waitpid()</code></a> syscall.
It places the exit code of the child process in the <code>status</code> parameter.
This argument is actually a bitfield containing more information that merely the exit code.
To retrieve the exit code, we use the <code>WEXITSTATUS</code> macro.
Keep in mind that <code>WEXITSTATUS</code> only makes sens if <code>WIFEXITED</code> is true, i.e. if the child process finished on its own and wasn&#x27;t killed by another one or by an illegal action (such as a seg fault or illegal instruction) for example.
Otherwise, <code>WEXITSTATUS</code> will return something meaningless.
You can view the rest of the information stored in the <code>status</code> bitfield <a href="https://linux.die.net/man/2/waitpid" target="_blank" rel="noopener noreferrer">in the man page</a>.</p><p>Now modify the example to do the following:</p><ol><li><p>Change the return value of the child process so that the value displayed by the parent is changed.</p></li><li><p>Create a child process of the newly created child.
Use a similar logic and a similar set of prints to those in the support code.
Take a look at the printed PIDs.
Make sure the PPID of the &quot;grandchild&quot; is the PID of the child, whose PPID is, in turn, the PID of the parent.</p></li></ol><p><strong>Moral of the story</strong>: Usually the execution flow is <code>fork()</code>, followed by <code>wait()</code> (called by the parent) <code>exit()</code>, called by the child.
The order of last 2 steps may be swapped.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="spreading-the-work-among-other-threads">Spreading the Work Among Other Threads<a class="hash-link" href="#spreading-the-work-among-other-threads" title="Direct link to heading">​</a></h3><p>Compile the code in <code>support/sum-array/d/sum_array_threads.d</code> and run it using 1, 2, 4 and 8 threads as you did before.
Each thread runs the <code>calculateArrayPartSum</code> function and then finishes.
Running times should be <em>slightly</em> smaller than the implementation using processes.
This slight time difference is caused by process creation actions, which are costlier than thread creation actions.
Because a process needs a separate virtual address space (VAS) and needs to duplicate some internal structures such as the file descriptor table and page table, it takes the operating system more time to create it than to create a thread.
On the other hand, threads belonging to the same process share the same VAS and, implicitly, the same OS-internal structures.
Therefore, they are more lightweight than processes.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-wait-for-me-once-more">Practice: Wait for Me Once More!<a class="hash-link" href="#practice-wait-for-me-once-more" title="Direct link to heading">​</a></h4><p>Go to <code>support/wait-for-me/wait_for_me_threads.d</code>.
Spawn a thread that executes the <code>negateArray()</code> function.
For now, do not wait for it to finish; simply start it.</p><p>Compile the code and run the resulting executable several times.
See that the negative numbers appear from different indices.
This is precisely the nondeterminism that we talked about <a href="#practice-wait-for-me">in the previous section</a>.</p><p>Now wait for that thread to finish and see that all the printed numbers are consistently negative.</p><p>As you can see, waiting is a very coarse form of synchronisation.
If we only use waiting, we can expect no speedup as a result of parallelism, because one thread must finish completely before another can continue.
We will discuss more fine-grained synchronisation mechanisms <a href="#synchronisation">later in this lab</a>.</p><p>Also, at this point, you might be wondering why this exercise is written in D, while <a href="#practice-wait-for-me">the same exercise, but with processes</a> was written in Python.
There is a very good reason for this and has to do with how threads are synchronized by default in Python.
You can find out what this is about <a href="#the-gil">in the Arena section</a>, after you have completed the <a href="#synchronisation">Synchronisation section</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="threads-vs-processes">Threads vs Processes<a class="hash-link" href="#threads-vs-processes" title="Direct link to heading">​</a></h3><p>So why use the implementation that spawns more processes if it&#x27;s slower than the one using threads?</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="safety">Safety<a class="hash-link" href="#safety" title="Direct link to heading">​</a></h4><p>Compile and run the two programs in <code>support/sum-array-bugs/seg-fault/</code>, first with 2 processes and threads and then with 4.
They do the same thing as before: compute the sum the elements in an array, but with a twist: each of them contains a bug causing a seg fault.
Notice that <code>sum_array_threads</code> doesn&#x27;t print anything with 4 threads, but merely a &quot;Segmentation fault&quot; message.
On the other hand, <code>sum_array_processes</code> prints a sum and a running time, albeit different from the sums we&#x27;ve seen so far.</p><p>The reason is that signals such as <code>SIGSEGV</code>, which is used when a segmentation fault happens affect the entire process that handles them.
Therefore, when we split our workload between several threads and one of them causes an error such as a seg fault, that error is going to terminate the entire process.
The same thing happens when we use processes instead of threads: one process causes an error, which gets it killed, but the other processes continue their work unhindered.
This is why we end up with a lower sum in the end: because one process died too early and didn&#x27;t manage to write the partial sum it had computed to the <code>results</code> array.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-wait-for-it">Practice: Wait for It!<a class="hash-link" href="#practice-wait-for-it" title="Direct link to heading">​</a></h4><p>The process that spawns all the others and subsequently calls <code>waitpid</code> to wait for them to finish can also get their return codes.
Update the code in <code>support/sum-array-bugs/seg-fault/sum_array_processes.d</code> and modify the call to <code>waitpid</code> to obtain and investigate this return code.
Display an appropriate message if one of the child processes returns an error.</p><p>Remember to use the appropriate <a href="https://linux.die.net/man/2/waitpid" target="_blank" rel="noopener noreferrer">macros</a> for handling the <code>status</code> variable that is modified by <code>waitpid</code>, as it is a bitfield.
When a process runs into a system error, it receives a signal.
A signal is a means to interrupt the normal execution of a program from the outside.
It is associated with a number.
Use <code>kill -l</code> to find the full list of signals. </p><p><a href="/Lab/Compute/quiz/seg-fault-exit-code">Quiz</a></p><p>So up to this point we&#x27;ve seen that one advantage of processes is that they offer better safety than threads.
Because they use separate virtual address spaces, sibling processes are better isolated than threads.
Thus, an application that uses processes can be more robust to errors than if it were using threads.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="memory-corruption">Memory Corruption<a class="hash-link" href="#memory-corruption" title="Direct link to heading">​</a></h4><p>Because they share the same address space,  threads run the risk of corrupting each other&#x27;s data.
Take a look at the code in <code>support/sum-array-bugs/memory-corruption/python/</code>.
The two programs only differ in how they spread their workload.
One uses threads while the other uses processes.</p><p>Run both programs with and without memory corruption.
Pass any value as a third argument to trigger the corruption.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../sum-array-bugs/memory-corruption/python$ python3 memory_corruption_processes.py &lt;number_of_processes&gt;  # no memory corruption</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../sum-array-bugs/memory-corruption/python$ python3 memory_corruption_processes.py &lt;number_of_processes&gt; 1  # do memory corruption</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The one using threads will most likely print a negative sum, while the other displays the correct sum.
This happens because all threads refer the same memory for the array <code>arr</code>.
What happens to the processes is a bit more complicated.</p><p><a href="#copy-on-write">Later in this lab</a> we will see that initially, the page tables of all processes point to the same physical frames or <code>arr</code>.
When the malicious process tries to corrupt this array by <strong>writing data to it</strong>, the OS duplicates the original frames of <code>arr</code> so that the malicious process writes the corrupted values to these new frames, while leaving the original ones untouched.
This mechanism is called <strong>Copy-on-Write</strong> and is an OS optimisation so that memory is shared between the parent and the child process, until one of them attempts to write to it.
At this point, this process receives its own separate copies of the previously shared frames.</p><p>Note that in order for the processes to share the <code>sums</code> dictionary, it is not created as a regular dictionary, but using the <code>Manager</code> module.
This module provides some special data structures that are allocated in <strong>shared memory</strong> so that all processes can access them.
You can learn more about shared memory and its various implementations <a href="#shared-memory">in the Arena section</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="usage-of-processes-and-threads-in-apache2">Usage of Processes and Threads in <code>apache2</code><a class="hash-link" href="#usage-of-processes-and-threads-in-apache2" title="Direct link to heading">​</a></h2><p>We&#x27;ll take a look at how a real-world application - the <code>apache2</code> HTTP server - makes use of processes and threads.
Since the server must be able to handle multiple clients at the same time, it must therefore use some form of concurrency.
When a new client arrives, the server offloads the work of interacting with that client to another process or thread.</p><p>The choice of whether to use multiple processes or threads is not baked into the code.
Instead, <code>apache2</code> provides a couple of modules called MPMs (Multi-Processing Modules).
Each module implements a different concurrency model and the users can pick whatever module best fits their needs by editing the server configuration files.</p><p>The most common MPMs are</p><ul><li><code>prefork</code>: there are multiple worker processes, each process is single-threaded and handles one client request at a time</li><li><code>worker</code>: there are multiple worker processes, each process is multi-threaded, and each thread handles one client request at a time</li><li><code>event</code>: same as <code>worker</code> but designed to better handle some particular use cases</li></ul><p>In principle, <code>prefork</code> provides more stability and backwards compatibility, but it has a bigger overhead.
On the other hand, <code>worker</code> and <code>event</code> are more scalable, and thus able to handle more simultaneous connections, due to the usage of threads.
On modern systems <code>event</code> is almost always the default.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="apache2-live-action"><code>apache2</code> Live Action<a class="hash-link" href="#apache2-live-action" title="Direct link to heading">​</a></h3><p>Let&#x27;s run an actual instance of <code>apache2</code> and see how everything works.
Go to <code>support/apache2</code> and run <code>make run</code>.
This will start a container with <code>apache2</code> running inside.</p><p>Check that the server runs as expected:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~$ curl localhost:8080</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now go inside the container and take a look at running processes:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/apache2$ docker exec -it apache2-test bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root@56b9a761d598:/usr/local/apache2# ps -ef</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">UID          PID    PPID  C STIME TTY          TIME CMD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root           1       0  0 20:38 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1  0 20:38 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      10       1  0 20:38 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root          25       0  0 20:40 pts/1    00:00:00 bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root          31      25  0 20:40 pts/1    00:00:00 ps -ef</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We see 3 <code>httpd</code> processes.
The first one, running as root, is the main process, while the other 2 are the workers.</p><p>Let&#x27;s confirm that we are using the <code>event</code> mpm:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">root@56b9a761d598:/usr/local/apache2# grep mod_mpm conf/httpd.conf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LoadModule mpm_event_module modules/mod_mpm_event.so</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#LoadModule mpm_prefork_module modules/mod_mpm_prefork.so</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#LoadModule mpm_worker_module modules/mod_mpm_worker.so</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The <code>event</code> mpm is enabled, so we expect each worker to be multi-threaded.
Let&#x27;s check:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">root@56b9a761d598:/usr/local/apache2# ps -efL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">UID          PID    PPID     LWP  C NLWP STIME TTY          TIME CMD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root           1       0       1  0    1 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1       8  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      11  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      12  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      16  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      17  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      18  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       8       1      19  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1       9  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      14  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      15  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      20  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      21  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      22  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data       9       1      23  0    7 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root          24       0      24  1    1 20:56 pts/1    00:00:00 bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root          30      24      30  0    1 20:56 pts/1    00:00:00 ps -efL</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Indeed, each worker has 7 threads.
In fact, the number of threads per worker is configurable, as well as the number of initial workers.</p><p>When a new connection is created, it will be handled by whatever thread is available from any worker.
If all the threads are busy, then the server will spawn more worker processes (and therefore more threads), as long as the total number of threads is below some threshold, which is also configurable.</p><p>Let&#x27;s see this dynamic scaling in action.
We need to create a number of simultaneous connections that is larger than the current number of threads.
There is a simple script in <code>support/apache2/make_conn.py</code> to do this:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/apache2$ python3 make_conn.py localhost 8080</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Press ENTER to exit</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The script has created 100 connections and will keep them open until we press Enter.</p><p>Now, in another terminal, let&#x27;s check the situation inside the container:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/apache2$ docker exec -it apache2-test bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root@56b9a761d598:/usr/local/apache2# ps -efL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">UID          PID    PPID     LWP  C NLWP STIME TTY          TIME CMD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root           1       0       1  0    1 20:56 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      40  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      45  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      46  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      51  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      52  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      53  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      40       1      54  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      55  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      58  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      60  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      62  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      63  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      65  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data      55       1      66  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     109  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     115  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     116  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     121  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     122  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     123  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">www-data     109       1     124  0    7 21:07 pts/0    00:00:00 httpd -DFOREGROUND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root         146       0     146  0    1 21:10 pts/1    00:00:00 bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">root         152     146     152  0    1 21:10 pts/1    00:00:00 ps -efL</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We see a much larger number of threads, as expected.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="practice-investigate-apache2-using-strace">Practice: Investigate <code>apache2</code> Using <code>strace</code><a class="hash-link" href="#practice-investigate-apache2-using-strace" title="Direct link to heading">​</a></h3><p>Use <code>strace</code> to discover the server document root.
The document root is the path in the filesystem from where httpd serves all the files requested by the clients.</p><p>First you will have to stop the running container using <code>make stop</code>, then restart it with <code>make run-privileged</code>.</p><p>Then you will use <code>strace</code> inside the container to attach to the worker processes (use the <code>-p</code> option for this).
You will also have to use <code>-f</code> flag with <code>strace</code>, so that it will follow all the threads inside the processes.</p><p>After you have attached successfully to all worker processes, use the <code>curl</code> command to send a request, like the one in the beginning of this section.</p><p>Then check the <code>strace</code> output to see what files were opened by the server.</p><p><a href="/Lab/Compute/quiz/apache2-strace">Quiz</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h3><p>So far, you&#x27;ve probably seen that spawning a process can &quot;use&quot; a different program (hence the path in the args of <code>system</code> or <code>Popen</code>), but some languages such as Python allow you to spawn a process that executes a function from the same script.
A thread, however, can only start from a certain entry point <strong>within the current address space</strong>, as it is bound to the same process.
Concretely, a process is but a group of threads.
For this reason, when we talk about scheduling or synchronisation, we talk about threads.
A thread is, thus, an abstraction of a task running on a CPU core.
A process is a logical group of such tasks.</p><p>We can sum up what we&#x27;ve learned so far by saying that processes are better used for separate, independent work, such as the different connections handled by a server.
Conversely, threads are better suited for replicated work: when the same task has to be performed on multiple cores.
However, replicated work can also be suited for processes.
Distributed applications, however, leverage different processes as this allows them to run on multiple physical machines at once.
This is required by the very large workloads such applications are commonly required to process.</p><p>These rules are not set in stone, though.
Like we saw in the <code>apache2</code> example, the server uses multiple threads as well as multiple processes.
This provides a degree of stability - if one worker thread crashes, it will only crash the other threads belonging to the same process - while still taking advantage of the light resource usage inherent to threads.</p><p>This kind of trade-offs are a normal part in the development of real-world applications.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="copy-on-write">Copy-on-Write<a class="hash-link" href="#copy-on-write" title="Direct link to heading">​</a></h2><p>So far you know that the parent and child process have separate virtual address spaces.
But how are they created, namely how are they &quot;separated&quot;?
And what about the <strong>physical address space</strong>?
Of course we would like the stack of the parent, for example, to be physically distinct from that of the child so they can execute different functions and use different local variables.</p><p>But should <strong>all</strong> the PAS of the parent be distinct from that of the child?
What about some read-only memory sections, such as <code>.text</code> and <code>.rodata</code>?
And what about the heap, where the child <em>may</em> use some data previously written by the parent and then override it with its own data.</p><p>The answer to all of these questions is a core mechanism of multi-process operating systems called <strong>Copy-on-Write</strong>.
It works according to one very simple principle:</p><blockquote><p>The VAS of the child process initially points to the same PAS as that of the parent.
A (physical) frame is only duplicated by the child when it attempts to <strong>write</strong> data to it.</p></blockquote><p>This ensures that read-only sections remain shared, while writable sections are shared as long as their contents remain unchanged.
When changes happen, the process making the change receives a unique frame as a modified copy of the original frame <em>on demand</em>.</p><p>In the image below we have the state of the child and parent processes right after <code>fork()</code> returns in both of them.
See how each has its own VAS, both of them being mapped to (mostly) the same PAS.</p><p>When one process writes data to a writeable page (in our case, the child writes to a heap page), the frame to which it corresponds is first duplicated.
Then the process&#x27; page table points the page to the newly copied frame, as you can see in the image below.</p><p><strong>Be careful!</strong>
Do not confuse copy-on-write with demand paging.
Remember from the <a href="/data/">Data chapter</a> that demand paging means that when you allocate memory the OS allocates virtual memory that remains unmapped to physical memory until it&#x27;s used.
On the other hand, copy-on-write posits that the virtual memory is already mapped to some frames.
These frames are only duplicated when one of the processes attempts to write data to them.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice">Practice<a class="hash-link" href="#practice" title="Direct link to heading">​</a></h4><p>Now let&#x27;s see the copy-on-write mechanism in practice.
Keep in mind that <code>fork()</code> is a function used to create a process.</p><p>Open two terminals (or better: use <a href="https://github.com/tmux/tmux/wiki" target="_blank" rel="noopener noreferrer"><code>tmux</code></a>).
In one of them compile and run the code in <code>support/fork-faults/fork_faults.c</code>.
After each time you press <code>Enter</code> in the first terminal window, run the following command in the second window:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/fork-faults$ ps -o min_flt,maj_flt $(pidof fork_faults)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>It will show you the number of minor and major page faults performed by the <code>fork_faults</code> process and its child.</p><p><a href="/Lab/Compute/quiz/parent-faults-before-fork">Quiz 1</a></p><p>Note that after <code>fork()</code>-ing, there is a second row in the output of <code>ps</code>.
That corresponds to the child process.
The first one still corresponds to the parent.</p><p><a href="/Lab/Compute/quiz/child-faults-after-write">Quiz 2</a></p><p>Now it should be clear how demand paging differs from copy-on-write.
Shared memory is a similar concept.
It&#x27;s a way of marking certain allocated pages so that copy-on-write is disabled.
As you may imagine, changes made by the parent to this memory are visible to the child and vice-versa.
You can learn more about it <a href="#shared-memory">its dedicated section in the Arena</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="synchronisation">Synchronisation<a class="hash-link" href="#synchronisation" title="Direct link to heading">​</a></h2><p>So far we&#x27;ve used threads and processes without wondering how to &quot;tell&quot; them how to access shared data.
Moreover, in order to make threads wait for each other, we simply had the main thread wait for the others to finish all their work.
But what if we want one thread to wait until another one simply performs some specific action after which it resumes its execution?
For this, we need to use some more complex synchronisation mechanisms.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="race-conditions">Race Conditions<a class="hash-link" href="#race-conditions" title="Direct link to heading">​</a></h3><p>For example, what if one thread wants to increase a global variable while another one wants to decrease it?
Let&#x27;s say the assembly code for increasing and decreasing the variable looks like the one in the snippet below.</p><div class="language-asm codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-asm codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">increase:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mov eax, [var]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inc eax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mov [var], eax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decrease:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mov eax, [var]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dec eax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mov [var], eax</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Imagine both threads executed <code>mov eax, [var]</code> at the same time.
Then each would independently increase its (<strong>non-shared</strong>) <code>eax</code> register.
In the end, the final value of <code>var</code> depends on which thread executes <code>mov [var], eax</code> <em>last</em>.
So it&#x27;s kind of a reversed race.
The thread that runs the slowest &quot;wins&quot; this race and writes the final value of <code>var</code>.
But this is up to the scheduler and is non-deterministic.
Such undefined behaviours can cripple the execution of a program if <code>var</code> is some critical variable.</p><p>Let&#x27;s see this bug in action.
Go to <code>support/race-condition/d/race_condition.d</code>, compile and run the code a few times.
It spawns to threads that do exactly what we&#x27;ve talked about so far: one thread increments <code>var</code> 10 million times, while the other decrements it 10 million times.</p><p>As you can see from running the program, the differences between subsequent runs can be substantial.
To fix this, we must ensure that <strong>only one thread</strong> can execute either <code>var++</code> or <code>var--</code> at any time.
We call these code sections <strong>critical sections</strong>.
A critical section is a piece of code that can only be executed by <strong>one thread</strong> at a time.
So we need some sort of <em>mutual exclusion mechanism</em> so that when one thread runs the critical section, the other has to <strong>wait</strong> before entering it.
This mechanism is called a <strong>mutex</strong>, whose name comes from &quot;mutual exclusion&quot;.</p><p>Go to <code>support/race-condition/d/race_condition_mutex.d</code> and notice the differences between this code and the buggy one.
We now use a <code>Mutex</code> variable which we <code>lock()</code> at the beginning of a critical section and we <code>unlock()</code> at the end.
Generally speaking <code>lock()</code>-ing a mutex makes a thread enter a critical section, while calling <code>unlock()</code> makes the thread leave said critical section.
Therefore, as we said previously, the critical sections in our code are <code>var--</code> and <code>var++</code>.
Run the code multiple times to convince yourself that in the end, the value of <code>var</code> will always be 0.</p><p>Mutexes contain an internal variable which can be either 1 (locked) or 0 (unlocked).
When a thread calls <code>lock()</code>, it attempts to set that variable to 1.
If it was 0, the thread sets it to 1 and proceeds to execute the critical section.
Otherwise, it <strong>suspends its execution</strong> and waits until that variable is set to 0 again.</p><p>When calling <code>unlock()</code>, the internal variable is set to 0 and all waiting threads are woken up to try to acquire the mutex again.
<strong>Be careful:</strong> It is generally considered unsafe and <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_lock.html" target="_blank" rel="noopener noreferrer">in many cases undefined behaviour</a> to call <code>unlock()</code> from a different thread than the one that acquired the lock.
So the general workflow should look something like this:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">within a single thread:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mutex.lock()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // do atomic stuff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mutex.unlock()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="synchronisation---overhead">Synchronisation - Overhead<a class="hash-link" href="#synchronisation---overhead" title="Direct link to heading">​</a></h4><blockquote><p>There ain&#x27;t no such thing as a free lunch</p></blockquote><p>This saying is also true for multithreading.
Running threads in parallel is nice and efficient, but synchronisation always comes with a penalty: overhead.
Use the <code>time</code> command to record the running times of <code>race_condition</code> and <code>race_condition_mutex</code>.
Notice that those of <code>race_condition_mutex</code> are larger than those of <code>race_condition</code>.</p><p>The cause of this is that now when one thread is executing the critical section, the other has to wait and do nothing.
Waiting means changing its state from RUNNING to WAITING, which brings further overhead from the scheduler.
This latter overhead comes from the <strong>context switch</strong>s that is necessary for a thread to switch its state from RUNNING to WAITING and back.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-wrap-the-whole-for-statements-in-critical-sections">Practice: Wrap the Whole <code>for</code> Statements in Critical Sections<a class="hash-link" href="#practice-wrap-the-whole-for-statements-in-critical-sections" title="Direct link to heading">​</a></h4><p>Move the calls to <code>lock()</code> and <code>unlock()</code> outside the <code>for</code> statements so that the critical sections become the entire statement.
Measure the time spent now by the code and compare it with the times recorded when the critical sections were made up of only <code>var--</code> and <code>var++</code>.</p><p><a href="/Lab/Compute/quiz/coarse-vs-granular-critical-section">Quiz</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="atomics">Atomics<a class="hash-link" href="#atomics" title="Direct link to heading">​</a></h3><p>So now we know how to use mutexes.
And we know that mutexes work by using an internal variable that can be either 1 (locked) or 0 (unlocked).
But how does <code>lock()</code> actually set that variable to 1?
How does it avoid a race condition in case another thread also wants to set it to 1?</p><p>We need a guarantee that anyone &quot;touching&quot; that variable does so &quot;within its own critical section&quot;.
But now we need a critical section to implement a critical section...
To solve this circular problem, we make use of a very common <em>Deus ex Machina</em>: <strong>hardware support</strong>.</p><p>Modern processors are capable of <em>atomically</em> accessing data, either for reads or writes.
An atomic action is and indivisible sequence of operations that a thread runs without interference from others.
Concretely, before initiating an atomic transfer on one of its data buses, the CPU first makes sure all other transfers have ended, then <strong>locks</strong> the data bus by stalling all cores attempting to transfer data on it.
This way, one thread obtains <strong>exclusive</strong> access to the data bus while accessing data.
As a side note, the critical sections in <code>support/race-condition/race_condition_mutex.d</code> are also atomic once they are wrapped between calls to <code>lock()</code> and <code>unlock()</code>. </p><p>As with every hardware feature, the x86 ISA exposes the <code>lock</code> instruction, which makes a given instruction run atomically.
You can play with it <a href="#atomic-assembly">in the Arena</a>.</p><p>Compilers provide support for such hardware-level atomic operations.
GCC exposes <a href="https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html" target="_blank" rel="noopener noreferrer">builtins</a> such as <code>__atomic_load()</code>, <code>__atomic_store()</code>, <code>__atomic_compare_exchange()</code> and many others.
All of them rely on the mechanism described above.</p><p>In D, this functionality is implemented in the <code>core.atomic</code> module.
Go to <code>support/race-condition/d/race_condition_atomic.d</code> and complete the function <code>decrementVar()</code>.
Compile and run the code.
Now measure its running time against the mutex implementations.
It should be somewhere between <code>race_condition.d</code> and <code>race_condition_mutex.d</code>.</p><p>So using the hardware support is more efficient, but it can only be leveraged for simple, individual instructions, such as loads and stores.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="semaphores">Semaphores<a class="hash-link" href="#semaphores" title="Direct link to heading">​</a></h3><p>Up to know we&#x27;ve learned how to create critical sections that can be accessed by <strong>only one thread</strong> at a time.
These critical sections revolved around <strong>data</strong>.
Whenever we define a critical section, there is some specific data to which we cannot allow parallel access.
The reason why we can&#x27;t allow it is, in general, data integrity, as we&#x27;ve seen in our examples in <code>support/race-condition/</code></p><p>But what if threads need to count?
Counting is inherently thread-unsafe because it&#x27;s a <em>read-modify-write</em> operation.
We read the counter, increment (modify) it and then write it back.
Think about our example with <a href="#usage-of-processes-and-threads-in-apache2"><code>apache2</code></a>
Let&#x27;s say a <code>worker</code> has created a <em>pool</em> of 3 threads.
They are not doing any work initially;
they are in the WAITING state.
As clients initiate connections, these threads are picked up and are used to serve <strong>at most 3</strong> connections at a time.
But the number of connections may be arbitrarily large.
Therefore, we need a way to keep track of it.
When serving a client, a thread should decrement it to inform the others that a connection has been finished.
In short, we need a counter that the dispatcher increments and that worker threads decrement.</p><p>Such a counter could be implemented using a <strong>semaphore</strong>.
For simplicity&#x27;s sake, you can view a semaphore as simply a mutex whose internal variable can take any value and acts like a counter.
When a thread attempts to <code>acquire()</code> a semaphore, it will wait if this counter is less than or equal to 0.
Otherwise, the thread <strong>decrements</strong> the internal counter and the function returns.
The opposite of <code>acquire()</code> is <code>release()</code>, which increases the internal counter by a given value (by default 1).</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-apache2-simulator---semaphore">Practice: <code>apache2</code> Simulator - Semaphore<a class="hash-link" href="#practice-apache2-simulator---semaphore" title="Direct link to heading">​</a></h4><p>Go to <code>support/apache2-simulator/apache2_simulator_semaphore.py</code>.
In the <code>main()</code> function we create a semaphore which we increment (<code>release()</code>) upon every new message.
Each thread decrements (<code>acquire()</code>) this semaphore to signal that it wants to retrieve a message from the list.
The retrieval means modifying a data structure, which is a critical section, so we use a <strong>separate</strong> mutex for this.
Otherwise, multiple threads could acquire the semaphore at the same time and try to modify the list at the same time.
Not good.</p><p>Locking this mutex (which in Python is called <code>Lock</code>) is done with the following statement: <code>with msg_mutex:</code>
This is a syntactic equivalent to:</p><div class="language-Python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">event.acquire()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">messages.append(msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">event.release()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="/Lab/Compute/quiz/semaphore-equivalent">Quiz</a></p><p>Since the length of the <code>messages</code> list is simply <code>len(messages)</code>, it may seem a bit redundant to use a semaphore to store essentially the same value.
In the next section, we&#x27;ll look at a more refined mechanism for our use case: <em>condition variables</em>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="conditions">Conditions<a class="hash-link" href="#conditions" title="Direct link to heading">​</a></h3><p>Another way we can implement our <code>apache2</code> simulator is to use a condition variable.
This one is probably the most intuitive synchronisation primitive.
It&#x27;s a means by which a thread can tell another one: &quot;Hey, wake up, <em>this</em> happened!&quot;.
So it&#x27;s a way for threads to notify each other.
For this reason, the main methods associated with conditions are <code>notify()</code> and <code>wait()</code>.
As you might expect, they are complementary:</p><ul><li><code>wait()</code> puts the thread in the WAITING state until it&#x27;s woken up by another one</li><li><code>notify()</code> wakes up one or more <code>wait()</code>-ing threads.
If <code>notify()</code> is called before any thread has called <code>wait()</code>, the first thread that calls it will continue its execution unhindered.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-apache2-simulator---condition">Practice: <code>apache2</code> Simulator - Condition<a class="hash-link" href="#practice-apache2-simulator---condition" title="Direct link to heading">​</a></h4><p>But this is not all, unfortunately.
Look at the code in <code>support/apache2-simulator/apache2_simulator_condition.py</code>.
See the main thread call notify once it reads the message.
Notice that this call is within a <code>with event:</code> so it acquires some mutex / semaphore.</p><p><code>acquire()</code> and <code>release()</code> are commonly associated with mutexes or semaphores.
What do they have to do with condition variables?</p><p>Well, a lock <code>Condition</code> variable also stores an inner lock (mutex).
It is this lock that we <code>acquire()</code> and <code>release()</code>.
In fact, the <a href="https://docs.python.org/3/library/threading.html#condition-objects" target="_blank" rel="noopener noreferrer">documentation</a> states we should only call <code>Condition</code> methods with its inner lock taken.</p><p>Why is this necessary?
Take a look at the <code>worker()</code> function.
After <code>wait()</code>-ing (we&#x27;ll explain the need for the loop in a bit), it extracts a message from the message queue.
This operation is <strong>not</strong> atomic, so it must be enclosed within a critical section.
Hence, the lock.</p><p><a href="/Lab/Compute/quiz/notify-only-with-mutex">Quiz</a></p><p>So now we know we cannot only use a mutex.
The mutex is used to access and modify the <code>messages</code> list atomically.
Now you might be thinking that this code causes a deadlock:</p><div class="language-Python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-Python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">with event:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    while len(messages) == 0:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        event.wait()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The thread gets the lock and then, if there are no messages, it switches its state to WAITING.
A classic deadlock, right?
No.
<code>wait()</code> also releases the inner lock of the <code>Condition</code> and being woken up reacquires it.
Neat!
And the <code>while</code> loop that checks if there are any new messages is necessary because <code>wait()</code> can return after an arbitrary long time.
Therefore, it&#x27;s necessary to check for messages again when waking up.</p><p>So now we have both synchronisation <strong>and</strong> signalling.
This is what conditions are for, ultimately.</p><p>Now that you understand the concept of synchronisation, you should apply it in a broader context.
<a href="#synchronisation---thread-safe-data-structure">In the Arena</a>, you&#x27;ll find an exercise asking you to make an existing arraylist implementation thread-safe.
Have fun!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="thread-local-storage-tls">Thread-Local Storage (TLS)<a class="hash-link" href="#thread-local-storage-tls" title="Direct link to heading">​</a></h2><p>First things first: what if we don&#x27;t want data to be shared between threads?
Are we condemned to have to worry about race conditions?
Well, no.</p><p>To protect data from race conditions &quot;by design&quot;, we can place in what&#x27;s called <strong>Thread-Local Storage (TLS)</strong>.
As its name implies, this is a type of storage that is &quot;owned&quot; by individual threads, as opposed to being shared among all threads.
<strong>Do not confuse it with copy-on-write</strong>.
TLS pages are always duplicated when creating a new thread and their contents are re-initialised.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-d---tls-by-default">Practice: D - TLS by Default<a class="hash-link" href="#practice-d---tls-by-default" title="Direct link to heading">​</a></h4><p>Take a look again at <code>support/race-condition/d/race_condition.d</code>, specifically at how <code>var</code> is declared:</p><div class="language-d codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-d codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">__gshared int var;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Have you wondered what the <code>__gshared</code> keyword does?
Well, for memory safety reasons, in D, all variables are by default <strong>not shared</strong> between threads.
We need to specifically ask the language to let us share a variable between threads.
We can do this using either the <code>__gshared</code> or <code>shared</code> keywords.
You&#x27;ve seed <code>shared</code> in <code>support/race-condition/d/race_condition_atomic.d</code>.</p><p>The difference between them is that <code>shared</code> only allows programmers read-modify-write the variable atomically, as we do in <code>support/race-condition/d/race_condition_atomic.d</code>.
Modify the <code>incrementVar()</code> function and increment <code>var</code> like you would any variable: <code>var++</code>.
Try to compile the code.
It fails.
The compiler is smart and tells you what to do instead:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Error: read-modify-write operations are not allowed for `shared` variables</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Use `core.atomic.atomicOp!&quot;+=&quot;(var, 1)` instead</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><code>__gshared</code> is a rawer version of <code>shared</code>.
It doesn&#x27;t forbid anything.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-c---tls-on-demand">Practice: C - TLS on Demand<a class="hash-link" href="#practice-c---tls-on-demand" title="Direct link to heading">​</a></h4><p>The perspective of C towards TLS is opposed to that of D: in C/C++ everything is shared by default.
This makes multithreading easier and more lightweight to implement than in D, because synchronisation is left entirely up to the developer, at the cost of potential unsafety.</p><p>Of course we can specify that some data belongs to the TLS, by preceding the declaration of a variable with <code>__thread</code> keyword.
First, compile and run the code in <code>support/race-condition/c/race_condition_tls.c</code> a few times.
As expected, the result is different each time.</p><ol><li>Modify the declaration of <code>var</code> and add the <code>__thread</code> keyword to place the variable in the TLS of each thread.
Recompile and run the code a few more times.
You should see that in the end, <code>var</code> is 0.</li></ol><p><a href="/Lab/Compute/quiz/tls-synchronization">Quiz 1</a></p><p><a href="/Lab/Compute/quiz/tls-var-copies">Quiz 2</a></p><ol start="2"><li><p>Print the address and value of <code>var</code> in each thread.
See that they differ.</p></li><li><p>Modify the value of <code>var</code> in the <code>main()</code> function before calling <code>pthread_create()</code>.
Notice that the value doesn&#x27;t propagate to the other threads.
This is because, upon creating a new thread, its TLS is initialised. </p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="scheduling">Scheduling<a class="hash-link" href="#scheduling" title="Direct link to heading">​</a></h2><ul><li><a href="https://github.com/kissen/threads" target="_blank" rel="noopener noreferrer">https://github.com/kissen/threads</a></li><li><a href="https://www.schaertl.me/posts/a-bare-bones-user-level-thread-library/" target="_blank" rel="noopener noreferrer">https://www.schaertl.me/posts/a-bare-bones-user-level-thread-library/</a></li></ul><p>Up to now we know that the OS decides which <strong>thread</strong> (not process) runs on each CPU core at each time.
Now we&#x27;ll learn about the component that performs this task specifically: <strong>the scheduler</strong>.</p><p>There are thousands of threads running at any time in a modern OS.
The job of the scheduler is to run and pause threads as well as allocate them to the CPU cores, with the following goals:</p><ul><li><strong>fairness</strong>: we do want all threads to get the same chance to run, i.e. run for about the same amount of time</li><li><strong>throughput</strong>: we want to run as many threads to completion so as to complete as many tasks as we can</li></ul><p>To do this, the scheduler must decide, at given times, to suspend a thread, save its current state and let another one run in its place.
This event is called a <strong>context switch</strong>.
A context switch means changing the state of one thread (the replaced thread) from RUNNING to WAITING and the state of the replacement thread from READY / WAITING to RUNNING.</p><ul><li>Quiz?</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="user-level-vs-kernel-level-threads">User-Level vs Kernel-Level Threads<a class="hash-link" href="#user-level-vs-kernel-level-threads" title="Direct link to heading">​</a></h3><p>There are two types of threads.
The threads you&#x27;ve used so far are <strong>kernel-level threads (KLT)</strong>.
They are created and scheduled in the kernel of the OS.
One of the most important of their features is that they offer true parallelism.
With KLTs, we can truly run a program on all the cores of our CPU at once.
But we must pay a price for this: scheduling them is very complex and context switches are costly (in terms of time), especially when switching threads belonging to different processes. </p><p>By contrast, <strong>user-level threads (ULT)</strong> are managed by the user space.
More of the ULTs created by a program are generally mapped to the same kernel thread.
If a process only creates ULTs, then they will all be mapped to the single, main kernel thread of the process.
So if we cannot run code in parallel with ULTs, then why use them?
Well, for I/O-intensive programs (those that do lots of network calls or file operations like reads and writes - web servers are a good example), threads are expected to perform lots of blocking calls, which causes context switches.
In such cases, user-level threads may be useful as context switches bring less overhead between user-level threads.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="practice-user-level-threads-scheduler">Practice: User-Level Threads Scheduler<a class="hash-link" href="#practice-user-level-threads-scheduler" title="Direct link to heading">​</a></h3><p>Go to <code>support/scheduler</code>.
It contains a minimalist <strong>user-level threads</strong> scheduler.
Compiling it produces a shared library called <code>libult.so</code>.
You can also consult its <a href="https://www.schaertl.me/posts/a-bare-bones-user-level-thread-library/" target="_blank" rel="noopener noreferrer">documentation</a>.
It explains the API as well as its implementation.
The API exposed by the scheduling library is very simple.
It is only made up of 3 functions:</p><ul><li><code>threads_create()</code> creates a new ULT</li><li><code>threads_exit()</code> moves the current ULT to the COMPLETED state</li><li><code>threads_join()</code> waits for a given thread to end and saves its return value in the <code>result</code> argument</li></ul><p>Look inside <code>support/libult/threads.c</code>.
Here you will find the 3 functions mentioned above.</p><p>The scheduler only uses 3 states: RUNNING, READY, COMPLETED.</p><p><a href="/Lab/Compute/quiz/number-of-running-ults">Quiz</a></p><p>The threads in the READY and COMPLETED states are kept in 2 separate queues.
When the scheduler wants to run a new thread, it retrieves it from the READY queue.
When a thread ends its execution, it is added to the COMPLETED queue, together with its return value.</p><p><a href="/Lab/Compute/quiz/why-use-completed-queue">Quiz</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="thread-control-block">Thread Control Block<a class="hash-link" href="#thread-control-block" title="Direct link to heading">​</a></h3><p>Let&#x27;s dissect the <code>threads_create()</code> function a bit.
It first initialises its queues and the timer for preemption.
We&#x27;ll discuss preemption <a href="#preemption">in the next section</a>.
After performing initialisations, the function creates a <code>TCB</code> object.
TCB stands for <strong>Thread Control Block</strong>.</p><p>During the <a href="/Lab/lecture/">lecture</a>, you saw that the kernel stores one instance of a <a href="https://elixir.bootlin.com/linux/v5.19.11/source/include/linux/sched.h#L726" target="_blank" rel="noopener noreferrer"><code>task_struct</code></a> for each thread.
Remember that its most important fields are:</p><div class="language-C codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-C codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">struct task_struct {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    unsigned int                    __state;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    void                           *stack;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    unsigned int                    flags;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int                             on_cpu;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int                             prio;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /* Scheduler information */</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct sched_entity             se;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    const struct sched_class        *sched_class;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /* The VAS: memory mappings */</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct mm_struct                *mm;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int                             exit_state;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    int                             exit_code;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pid_t                           pid;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct task_struct __rcu        *parent;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /* Child processes */</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct list_head                children;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    /* Open file information */</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    struct files_struct             *files;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>As you can see, this <code>struct</code> stores <em>metadata</em> regarding a given thread.
The same is true about the <code>TCB</code> in <code>libult.so</code>:</p><div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">typedef</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> id</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token class-name">ucontext_t</span><span class="token plain"> context</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool has_dynamic_stack</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">start_routine</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">argument</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">return_value</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> TCB</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>It stores the thread ID (tid - <code>id</code>), similar to the PID of a process.
It stores a pointer to the function passed as argument to <code>threads_create()</code> (<code>start_routine</code>), as well as the argument (<code>argument</code>) and the returned value (<code>return_value</code>) of said function.</p><p>In addition, the <code>TCB</code> stores a <code>context</code>.
From the <a href="https://pubs.opengroup.org/onlinepubs/7908799/xsh/ucontext.h.html" target="_blank" rel="noopener noreferrer">man page of the <code>ucontext.h</code> header</a>, we can see this type is a <code>struct</code> that stores a pointer to the stack of the current thread (<code>uc_stack</code>).
This is similar to the <code>stack</code> pointer in the <code>task_struct</code> above.
In short, we can say a context defines an execution unit, such as a thread.
<strong>This is why changing the running thread is called a context switch.</strong></p><p>Let&#x27;s compare this context with another thread implementation, from <a href="https://unikraft.org/" target="_blank" rel="noopener noreferrer">Unikraft</a>.
We&#x27;ll look at the <a href="https://github.com/unikraft/unikraft/blob/9bf6e63314a401204c02597834fb02f63a29aaf4/lib/uksched/include/uk/thread.h#L55-L76" target="_blank" rel="noopener noreferrer"><code>uk_thread</code></a> <code>struct</code>, which is the TCB used in Unikraft:</p><div class="language-c codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-c codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">uk_thread</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">char</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">name</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">stack</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">tls</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">ctx</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">UK_TAILQ_ENTRY</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">uk_thread</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> thread_list</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token class-name">uint32_t</span><span class="token plain"> flags</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    __snsec wakeup_time</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bool detached</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">uk_waitq</span><span class="token plain"> waiting_threads</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">struct</span><span class="token plain"> </span><span class="token class-name">uk_sched</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">sched</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">entry</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">arg</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">prv</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>There are some visible similarities between the two TCBs.</p><p><a href="/Lab/Compute/quiz/tcb-libult-unikraft">Quiz</a></p><p>Therefore, the workflow for creating and running a thread goes like this:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">main thread</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    `--&gt; threads_create()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        |--&gt; tcb_new()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            `--&gt; makecontext()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            `--&gt; handle_thread_start() - called using the context</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                |--&gt; start_routine() - the thread runs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                            `--&gt; threads_exit()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Compile and run the code in <code>support/libult/test_ult.c</code>.
If you encounter the following error when running <code>test_ult</code>, remember what you learned about the loader and using custom shared libraries in the <a href="/software-stack/lab">Software Stack lab</a>.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./test_ult: error while loading shared libraries: libult.so: cannot open shared object file: No such file or directory</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><blockquote><p>Hint: Use the <code>LD_LIBRARY_PATH</code> variable.</p></blockquote><p>Notice that the threads run their code and alternatively, because their prints appear interleaved.
<a href="#preemption">In the next section</a>, we&#x27;ll see how this is done.</p><p><a href="/Lab/Compute/quiz/ult-thread-ids">Quiz</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="preemption">Preemption<a class="hash-link" href="#preemption" title="Direct link to heading">​</a></h3><p>All schedulers can be split into two categoriesThere are two types of schedulers: <strong>preemptive</strong> and <strong>cooperative</strong>.
When discussing this distinction, we need to first define the notion of <strong>yielding</strong>.
Yielding the CPU means that a thread suspends its own execution and enters the WAITING or READY state, either as a result of a blocking call (I/O operations or calling the scheduler&#x27;s <code>yield()</code> function directly).
So, yielding the CPU triggers a context switch whereby the current thread stops running and another one resumes or starts running in its place.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="cooperative-scheduling">Cooperative Scheduling<a class="hash-link" href="#cooperative-scheduling" title="Direct link to heading">​</a></h4><p>Cooperative scheduling relies on the fact that threads themselves would yield the CPU at some point.
If threads don&#x27;t abide by this convention, they end up monopolising the CPU (since there is no one to suspend them) and end up starving the others.
You can get a feel of this behaviour by running the cooperative <a href="https://github.com/unikraft/unikraft/blob/staging/lib/ukschedcoop/schedcoop.c" target="_blank" rel="noopener noreferrer">scheduler from Unikraft</a> in the <a href="/lecture/demo/cooperative-scheduling">lecture demos</a>.</p><p>This type of schedulers have the advantage of being lightweight, thus resulting in less overhead caused by context switches.
However, as we&#x27;ve already stated, they rely on the &quot;good will&quot; of threads to yield the CPU at some point.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="preemptive-scheduling">Preemptive Scheduling<a class="hash-link" href="#preemptive-scheduling" title="Direct link to heading">​</a></h4><p>Preemptive scheduling solve the issue stated above by leaving the task of suspending the currently RUNNING thread and replacing it with another one from the READY queue up to the scheduler.
This increases its complexity and the duration of context switches, but threads now are not required to worry about yielding themselves and can focus on running their code and performing the task for which they are created.</p><p>Preemptive schedulers assign only allow threads to run for a maximum amount of time, called <strong>time slice</strong> (usually a few milliseconds).
They use timers which fire when a new time slice passes.
The firing of one such timer causes a context switch whereby the currently RUNNING thread is <em>preempted</em> (i.e. suspended) and replaced with another one.</p><p><a href="/Lab/Compute/quiz/type-of-scheduler-in-libult">Quiz</a></p><p>Look at the <code>init_profiling_timer()</code> function.
It creates a timer that generates a <code>SIGPROF</code> signal and then defines a handler (the <code>handle_sigprof()</code> function) that is executed whenever the <code>SIGPROF</code> signal is received.</p><p><a href="/Lab/Compute/quiz/time-slice-value">Quiz</a></p><p>It is this handler that performs the context switch per se.
Look at its code.
It first saves the context of the currernt thread:</p><div class="language-C codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-C codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ucontext_t *stored = &amp;running-&gt;context;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ucontext_t *updated = (ucontext_t *) context;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stored-&gt;uc_flags = updated-&gt;uc_flags;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stored-&gt;uc_link = updated-&gt;uc_link;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stored-&gt;uc_mcontext = updated-&gt;uc_mcontext;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stored-&gt;uc_sigmask = updated-&gt;uc_sigmask;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Then it places current thred in the <code>ready</code> queue and replaces it with the first thread in the same queue.
This algorithm (that schedules the first thread in the READY queue) is called <em>Round-Robin</em>:</p><div class="language-C codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-C codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">if (queue_enqueue(ready, running) != 0) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    abort();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if ((running = queue_dequeue(ready)) == NULL) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    abort();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The new <code>running</code> thread is resumed upon setting the current context to it:</p><div class="language-C codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-C codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">if (setcontext(&amp;running-&gt;context) == -1) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    abort();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This is how scheduling is done!</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-another-time-slice">Practice: Another Time Slice<a class="hash-link" href="#practice-another-time-slice" title="Direct link to heading">​</a></h4><ol><li><p>Modify the time slice set to the timer to 2 seconds.
Re-run the code in <code>support/libult/test_ult.c</code>.
Notice that now no context switch happens between the 2 created threads because they end before the timer can fire.</p></li><li><p>Now change the <code>printer_thread()</code> function in <code>test_ult.c</code> to make it run for more than 2 seconds.
See that now the prints from the two threads appear intermingled.
Add prints to the <code>handle_sigprof()</code> function in <code>support/libult/threads.c</code> to see the context switch happen.</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="arena">Arena<a class="hash-link" href="#arena" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="threads-and-processes-clone">Threads and Processes: <code>clone</code><a class="hash-link" href="#threads-and-processes-clone" title="Direct link to heading">​</a></h3><p>Let&#x27;s go back to our initial demos that used threads and processes.
We&#x27;ll see that in order to create both threads and processes, the underlying Linux syscall is <code>clone</code>.
For this, we&#x27;ll run both <code>sum_array_threads</code> and <code>sum_array_processes</code> under <code>strace</code>.
As we&#x27;ve already established, we&#x27;re only interested in the <code>clone</code> syscall:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/sum-array/d$ strace -e clone ./sum_array_threads 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">clone(child_stack=0x7f60b56482b0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tid=[1819693], tls=0x7f60b5649640, child_tidptr=0x7f60b5649910) = 1819693</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">clone(child_stack=0x7f60b4e472b0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tid=[1819694], tls=0x7f60b4e48640, child_tidptr=0x7f60b4e48910) = 1819694</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../lab/support/sum-array/d$ strace -e clone ./sum_array_processes 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f7a4e346650) = 1820599</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f7a4e346650) = 1820600</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>We ran each program with an argument of 2, so we have 2 calls to <code>clone</code>.
Notice that in the case of threads, the <code>clone</code> syscall receives more arguments.
The relevant flags passed as arguments when creating threads are documented in <a href="https://man.archlinux.org/man/clone3.2.en" target="_blank" rel="noopener noreferrer"><code>clone</code>&#x27;s man page</a>:</p><ul><li><code>CLONE_VM</code>: the child and the parent process share the same VAS</li><li><code>CLONE_{FS,FILES,SIGHAND}</code>: the new thread shares the filesystem information, file and signal handlers with the one that created it
The syscall also receives valid pointers to the new thread&#x27;s stack and TLS, i.e. the only parts of the VAS that are distinct between threads (although they are technically accessible from all threads).</li></ul><p>By contrast, when creating a new process, the arguments of the <code>clone</code> syscall are simpler (i.e. fewer flags are present).
Remember that in both cases <code>clone</code> creates a new <strong>thread</strong>.
When creating a process, <code>clone</code> creates this new thread within a new separate address space.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="libraries-for-parallel-processing">Libraries for Parallel Processing<a class="hash-link" href="#libraries-for-parallel-processing" title="Direct link to heading">​</a></h3><p>In <code>support/sum-array/d/sum_array_threads.d</code> we spawned threads &quot;manually&quot; by using the <code>spawn</code> function.
This is <strong>not</strong> a syscall, but a wrapper over the most common thread-management API in POSIX-based operating systems (such as Linux, FreeBSD, macOS): POSIX Threads or <code>pthreads</code>.
By inspecting the <a href="https://github.com/dlang/phobos/blob/352258539ca54e640e862f79b2b8ec18aafa7d94/std/concurrency.d#L618-L622" target="_blank" rel="noopener noreferrer">implementation of <code>spawn</code></a>, we see that it creates a <code>Thread</code> object, on which it calls the <code>start()</code> method.
In turn, <a href="https://github.com/dlang/dmd/blob/cc117cd45c7d72ce5a87b775e65a9d13fa4d4424/druntime/src/core/thread/osthread.d#L454-L486" target="_blank" rel="noopener noreferrer"><code>start()</code> uses <code>pthread_create()</code></a> on POSIX systems.</p><p>Still, <code>pthread_create()</code> is not yet a syscall.
In order to see what syscall <code>pthread_create()</code> uses, check out <a href="#threads-and-processes-clone">this section at the end of the lab</a>.</p><p>Most programming languages provide a more advanced API for handling parallel computation.
D makes no exception.
Its standard library exposes the <a href="https://dlang.org/phobos/std_parallelism.html" target="_blank" rel="noopener noreferrer"><code>std.parallelism</code></a>, which provides a series of parallel processing functions.
One such function is <code>reduce</code> which splits an array between a given number of threads and applies a given operation to these chunks.
In our case, the operation simply adds the elements to an accumulator: <code>a + b</code>.
Follow and run the code in <code>support/sum-array/d/sum_array_threads_reduce.d</code>.</p><p>The number of threads is used within a <a href="https://dlang.org/phobos/std_parallelism.html#.TaskPool" target="_blank" rel="noopener noreferrer"><code>TaskPool</code></a>.
This structure is a thread manager (not scheduler).
It silently creates the number of threads we request and then <code>reduce</code> spreads its workload between these threads.</p><p>Now run the <code>sum_array_threads_reduce</code> binary using 1, 2, 4, and 8 threads as before.
You&#x27;ll see lower running times than <code>sum_array_threads</code> due to the highly-optimised code of the <code>reduce</code> function.
For this reason and because library functions are usually much better tested than your own code, it is always preferred to use a library function for a given task.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="shared-memory">Shared Memory<a class="hash-link" href="#shared-memory" title="Direct link to heading">​</a></h3><p>As you remember from the <a href="/data/">Data chapter</a>, one way to allocate a given number of pages is to use the <code>mmap()</code> syscall.
Let&#x27;s look at its <a href="https://man7.org/linux/man-pages/man2/mmap.2.html" target="_blank" rel="noopener noreferrer">man page</a>, specifically at the <code>flags</code> argument.
Its main purpose is to determine the way in which child processes interact with the mapped pages.</p><p><a href="/Lab/Compute/quiz/mmap-cow-flag">Quiz</a></p><p>Now let&#x27;s test this flag, as well as its opposite: <code>MAP_SHARED</code>.
Compile and run the code in <code>support/shared-memory/shared_memory.c</code>.</p><ol><li><p>See the value read by the parent id different from that written by the child.
Modify the <code>flags</code> parameter of <code>mmap()</code> so they are the same.</p></li><li><p>Create a semaphore in the shared page and use it to make the parent signal the child before it can exit.
Use the API defined in <a href="https://man7.org/linux/man-pages/man0/semaphore.h.0p.html" target="_blank" rel="noopener noreferrer"><code>semaphore.h</code></a>.
<strong>Be careful!</strong>
The value written and read previously by the child and the parent, respectively, must not change.</p></li></ol><p>One way of creating a shared semaphore is to place it within a shared memory area, as we&#x27;ve just done.
This only works between &quot;related&quot; processes.
If you want to share a semaphore or other types of memory between any two processes, you need filesystem support.
For this, you should use <strong>named semaphores</strong>, created using <a href="https://man7.org/linux/man-pages/man3/sem_open.3.html" target="_blank" rel="noopener noreferrer"><code>sem_open()</code></a>.
You&#x27;ll get more accustomed to such functions in the <a href="/app-interact/">Application Interaction chapter</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mini-shell">Mini-shell<a class="hash-link" href="#mini-shell" title="Direct link to heading">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="fist-step-system-dissected">Fist Step: <code>system</code> Dissected<a class="hash-link" href="#fist-step-system-dissected" title="Direct link to heading">​</a></h4><p>You already know that <code>system</code> calls <code>fork()</code> and <code>execve()</code> to create the new process.
Let&#x27;s see how and why.
First, we run the following command to trace the <code>execve()</code> syscalls used by <code>sleepy_creator</code>.
We&#x27;ll leave <code>fork()</code> for later.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../support/sleepy$ strace -e execve -ff -o syscalls ./sleepy_creator</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>At this point you will get two files whose names start with <code>syscalls</code>, followed by some numbers.
Those numbers are the PIDs of the parent and the child process.
Therefore, the file with the higher number contains logs of the <code>execve</code> and <code>clone</code> syscalls issued by the parent process, while
the other logs those two syscalls when made by the child process.
Let&#x27;s take a look at them.
The numbers below will differ from those on your system:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../support/sleepy:$ cat syscalls.2523393  # syscalls from parent process</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">execve(&quot;sleepy_creator&quot;, [&quot;sleepy_creator&quot;], 0x7ffd2c157758 /* 39 vars */) = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=2523394, si_uid=1052093, si_status=0, si_utime=0, si_stime=0} ---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ exited with 0 +++</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">student@os:~/.../support/sleepy:$ cat syscalls.2523394  # syscalls from child process</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">execve(&quot;/bin/sh&quot;, [&quot;sh&quot;, &quot;-c&quot;, &quot;sleep 10&quot;], 0x7ffd36253be8 /* 39 vars */) = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">execve(&quot;/usr/bin/sleep&quot;, [&quot;sleep&quot;, &quot;10&quot;], 0x560f41659d40 /* 38 vars */) = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+++ exited with 0 +++</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="/Lab/Compute/quiz/who-calls-execve-parent">Quiz</a></p><p>Now notice that the child process doesn&#x27;t simply call <code>execve(&quot;/usr/bin/sleep&quot; ...)</code>.
It first changes its virtual address space (VAS) to that of a <code>bash</code> process (<code>execve(&quot;/bin/sh&quot; ...)</code>) and then that <code>bash</code> process switches its VAS to <code>sleep</code>.
Therefore, calling <code>system(&lt;some_command&gt;)</code> is equivalent to running <code>&lt;some_command&gt;</code> in the command line.</p><p>With this knowledge in mind, let&#x27;s implement our own mini-shell.
Start from the skeleton code in <code>support/mini-shell/mini_shell.c</code>.
We&#x27;re already running our Bash interpreter from the command line, so there&#x27;s no need to <code>exec</code> another Bash from it.
Simply <code>exec</code> the command.</p><p><a href="/Lab/Compute/quiz/mini-shell-stops-after-command">Quiz</a></p><p>So we need a way to &quot;save&quot; the <code>mini_shell</code> process before <code>exec()</code>-ing our command.
Find a way to do this.</p><blockquote><p><strong>Hint</strong>:  You can see what <code>sleepy</code> does and draw inspiration from there.
Use <code>strace</code> to also list the calls to <code>clone()</code> perfromed by <code>sleepy</code> or its children.
<a href="#threads-and-processes-clone">Remember</a> what <code>clone()</code> is used for and use its parameters to deduce which of the two scenarios happens to <code>sleepy</code>. </p></blockquote><p><strong>Moral of the story</strong>: We can add another step to the moral of <a href="#practice-fork">our previous story</a>.
When spawning a new command, the call order is:</p><ul><li>parent: <code>fork()</code>, <code>exec()</code>, <code>wait()</code></li><li>child: <code>exit()</code></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="command-executor-in-another-language">Command Executor in Another language<a class="hash-link" href="#command-executor-in-another-language" title="Direct link to heading">​</a></h4><p>Now implement the same functionality (a Bash command executor) in any other language, other than C/C++.
Use whatever API is provided by your language of choice for creating and waiting for processes.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-gil">The GIL<a class="hash-link" href="#the-gil" title="Direct link to heading">​</a></h3><p>Throughout this lab you might have noticed that there were no thread exercises <em>in Python</em>.
If you did, you probably wondered why.
It&#x27;s not because Python does not support threads, because it does, but because of a mechanism called the <strong>Global Interpreter Lock</strong>, or GIL.
As its name suggests, this is a lock implemented inside most commonly used Python interpreter (CPython), which only allows <strong>one</strong> thread to run at a given time.
As a consequence, multithreaded programs written in Python run <strong>concurrently</strong>, not in parallel.
For this reason, you will see no speedup even when you run an embarrassingly parallel code in parallel.</p><p>However, keep in mind that this drawback does not make threads useless in Python.
They are still useful and widely used when a process needs to perform many IO-bound tasks (i.e.: tasks that involve many file reads / writes or network requests).
Such tasks run many blocking syscalls that require the thread to switch from the RUNNING state to WAITING.
Doing so voluntarily makes threads viable because they rarely run for their entire time slice and spend most of the time waiting for data.
So it doesn&#x27;t hurt them to run concurrently, instead of in parallel.</p><p>Do not make the confusion to believe threads in Python are <a href="#user-level-vs-kernel-level-threads">user-level threads</a>.
<a href="https://docs.python.org/3/library/threading.html#threading.Thread" target="_blank" rel="noopener noreferrer"><code>threading.Thread</code></a>s are kernel-level threads.
It&#x27;s just that they are forced to run concurrenntly by the GIL.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="practice-array-sum-in-python">Practice: Array Sum in Python<a class="hash-link" href="#practice-array-sum-in-python" title="Direct link to heading">​</a></h4><p>Let&#x27;s first probe this by implementing two parallel versions of the code in <code>support/sum-array/python/sum_array_sequential.py</code>.
One version should use threads and the other should use processes.
Run each of them using 1, 2, 4, and 8 threads / processes respectively and compare the running times.
Notice that the running times of the multithreaded implementation do not decrease.
This is because the GIL makes it so that those threads that you create essentially run sequentially.</p><p>The GIL also makes it so that individual Python instructions are atomic.
Run the code in <code>support/race-condition/python/race_condition.py</code>.
Every time, <code>var</code> will be 0 because the GIL doesn&#x27;t allow the two threads to run in parallel and reach the critical section at the same time.
This means that the instructions <code>var += 1</code> and <code>var -= 1</code> become atomic.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="but-why">But Why?<a class="hash-link" href="#but-why" title="Direct link to heading">​</a></h4><p>Unlike Bigfoot, or the Loch Ness monster, we have proof that the GIL is real.
At first glance, this seems like a huge disadvantage.
Why force threads to run sequentially?
The answer has to do with memory management.
In the <a href="/data">Data chapter</a>, you learned that one way of managing memory is via <em>garbage collection</em> (GC).
In Python, the GC uses reference counting, i.e. each object also stores the number of live pointers to it (variables that reference it).
You can see that this number needs to be modified atomically by the interpreter to avoid race conditions.
This involves adding locks to <strong>all</strong> Python data structures.
This large number of locks doesn&#x27;t scale for a language as large and open as Python.
In addition, it also introduces the risk of <em>deadlocks</em>.
You can read more on this topic <a href="https://realpython.com/python-gil/" target="_blank" rel="noopener noreferrer">in this article</a> and if you think eliminating the GIL looks like an easy task, which should have been done long ago, check the requirements <a href="https://wiki.python.org/moin/GlobalInterpreterLock" target="_blank" rel="noopener noreferrer">here</a>.
They&#x27;re not trivial to meet.</p><p>Single-threadedness is a common trope for interpreted languages to use some sort of GIL.
<a href="https://git.ruby-lang.org/ruby.git" target="_blank" rel="noopener noreferrer">Ruby MRI, the reference Ruby interpreter</a> uses a similar mechanism, called the <a href="https://ivoanjo.me/blog/2022/07/17/tracing-ruby-global-vm-lock/" target="_blank" rel="noopener noreferrer">Global VM Lock</a>.
JavaScript is even more straightforward: it is single-threaded by design, also for GC-related reasons.
It does, however support asynchronous actions, but these are executed on the same thread as every other code.
This is implemented by placing each instruction on a <a href="https://medium.com/swlh/what-does-it-mean-by-javascript-is-single-threaded-language-f4130645d8a9" target="_blank" rel="noopener noreferrer">call stack</a>. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="atomic-assembly">Atomic Assembly<a class="hash-link" href="#atomic-assembly" title="Direct link to heading">​</a></h3><p>No, this section is not about nukes, sadly :(.
Instead, we aim to get accustomed to the way in which the x86 ISA provides atomic instructions.</p><p>This mechanism looks very simple.
It is but <strong>one instruction prefix</strong>: <code>lock</code>.
It is not an instruction with its own separate opcode, but a prefix that slightly modifie the opcode of the following instructions to make the CPU execute it atomically (i.e. with exclusive access to the data bus).</p><p><code>lock</code> must only be place before an instruction that executes a <em>read-modify-write</em> action.
For example, we cannot place it before a <code>mov</code> instruction, as the action of a <code>mov</code> is simply <code>read</code> or <code>write</code>.
Instead, we can place it in front of an <code>inc</code> instruction if its operand is memory.</p><p>Look at the code in <code>support/race-condition/asm/race_condition_lock.S</code>.
It&#x27;s an Assembly equivalent of the code you&#x27;ve already seen many times so far (such as <code>support/race-condition/d/race_condition.d</code>).
Assemble and run it a few times.
Notice the different results you get.</p><p>Now add the <code>lock</code> prefix before <code>inc</code> and <code>dec</code>.
Reassemble and rerun the code.
And now we have synchronised the two threads by leveraging CPU support.</p><ul><li>TODO add this section to the lecture</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="synchronisation---thread-safe-data-structure">Synchronisation - Thread-Safe Data Structure<a class="hash-link" href="#synchronisation---thread-safe-data-structure" title="Direct link to heading">​</a></h3><p>Now it&#x27;s time for a fully practical exercise.
Go to <code>support/CLIST/</code>.
In the file <code>clist.c</code> you&#x27;ll find a simple implementation of an array list.
Although correct, it is not (yet) thread-safe.</p><p>The code in <code>test.c</code> verifies its single-threaded correctness while the one in <code>test_parallel.c</code> verifies it works properly with multiple threads.
Your task is to synchronise this data structure using whichever primitives you like.
Try to keep the implementation efficient.
Aim to decrease your running times as much as you can.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/Lab/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Lab</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-role-of-the-operating-system" class="table-of-contents__link toc-highlight">The Role of the Operating System</a></li><li><a href="#processes" class="table-of-contents__link toc-highlight">Processes</a></li><li><a href="#sum-of-the-elements-in-an-array" class="table-of-contents__link toc-highlight">Sum of the Elements in an Array</a><ul><li><a href="#spreading-the-work-among-other-processes" class="table-of-contents__link toc-highlight">Spreading the Work Among Other Processes</a></li><li><a href="#spreading-the-work-among-other-threads" class="table-of-contents__link toc-highlight">Spreading the Work Among Other Threads</a></li><li><a href="#threads-vs-processes" class="table-of-contents__link toc-highlight">Threads vs Processes</a></li></ul></li><li><a href="#usage-of-processes-and-threads-in-apache2" class="table-of-contents__link toc-highlight">Usage of Processes and Threads in <code>apache2</code></a><ul><li><a href="#apache2-live-action" class="table-of-contents__link toc-highlight"><code>apache2</code> Live Action</a></li><li><a href="#practice-investigate-apache2-using-strace" class="table-of-contents__link toc-highlight">Practice: Investigate <code>apache2</code> Using <code>strace</code></a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#copy-on-write" class="table-of-contents__link toc-highlight">Copy-on-Write</a></li><li><a href="#synchronisation" class="table-of-contents__link toc-highlight">Synchronisation</a><ul><li><a href="#race-conditions" class="table-of-contents__link toc-highlight">Race Conditions</a></li><li><a href="#atomics" class="table-of-contents__link toc-highlight">Atomics</a></li><li><a href="#semaphores" class="table-of-contents__link toc-highlight">Semaphores</a></li><li><a href="#conditions" class="table-of-contents__link toc-highlight">Conditions</a></li></ul></li><li><a href="#thread-local-storage-tls" class="table-of-contents__link toc-highlight">Thread-Local Storage (TLS)</a></li><li><a href="#scheduling" class="table-of-contents__link toc-highlight">Scheduling</a><ul><li><a href="#user-level-vs-kernel-level-threads" class="table-of-contents__link toc-highlight">User-Level vs Kernel-Level Threads</a></li><li><a href="#practice-user-level-threads-scheduler" class="table-of-contents__link toc-highlight">Practice: User-Level Threads Scheduler</a></li><li><a href="#thread-control-block" class="table-of-contents__link toc-highlight">Thread Control Block</a></li><li><a href="#preemption" class="table-of-contents__link toc-highlight">Preemption</a></li></ul></li><li><a href="#arena" class="table-of-contents__link toc-highlight">Arena</a><ul><li><a href="#threads-and-processes-clone" class="table-of-contents__link toc-highlight">Threads and Processes: <code>clone</code></a></li><li><a href="#libraries-for-parallel-processing" class="table-of-contents__link toc-highlight">Libraries for Parallel Processing</a></li><li><a href="#shared-memory" class="table-of-contents__link toc-highlight">Shared Memory</a></li><li><a href="#mini-shell" class="table-of-contents__link toc-highlight">Mini-shell</a></li><li><a href="#the-gil" class="table-of-contents__link toc-highlight">The GIL</a></li><li><a href="#atomic-assembly" class="table-of-contents__link toc-highlight">Atomic Assembly</a></li><li><a href="#synchronisation---thread-safe-data-structure" class="table-of-contents__link toc-highlight">Synchronisation - Thread-Safe Data Structure</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://curs.upb.ro" target="_blank" rel="noopener noreferrer" class="footer__link-item">Main site<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ocw.cs.pub.ro/courses/so" target="_blank" rel="noopener noreferrer" class="footer__link-item">OCW<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/sisteme.de.operare/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 SO Team</div></div></div></footer></div>
<script src="/assets/js/runtime~main.55192f6a.js"></script>
<script src="/assets/js/main.1070cd52.js"></script>
</body>
</html>